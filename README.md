# Scraping EDGAR data using Google DataFlow and Buckets


<img src="https://github.com/kashishshah881/data-pipeline/blob/master/img1.jpeg" width="1000">

The main motto of this project is to scrape data using Google Cloud DataFlow and Apache Beam.


### Result:

The **5 Day Rolling Mean of Adjacent Close** has the most effect on the next day adjacent close stock price by **18%**

The Image at the start gives the returns based on **5 Day Rolling Mean of Adjacent Close**



## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

```
git clone https://github.com/kashishshah881/random-forest-regressions.git

```

### Prerequisites

What things you need to install the software:

```
Python3.5+
```

### Installing

Run These Commands on the terminal
```
pip3 install jupyter numpy pandas matplotlib quantrautil sklearn
```
Once Everything is installed successfully run

```
jupyter notebook
```



## Authors

* **[Kashish Shah](www.kashishshah.com)**


## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details


